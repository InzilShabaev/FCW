{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e9043d11-5700-484a-b30f-184fd647808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "05b6ca14-27da-4b20-810d-f23b81dd50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as immg\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6a7ee902-8ed2-4fe0-9a70-4c327f740f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание коннекта с БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6a5a46fe-7a94-48e3-b0ad-dc6ce3a8f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database=\"FCW\", user=\"postgres\",\n",
    "    password=\"123\", host=\"172.17.0.2\", port=5432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c6b79dc0-66c3-463d-8841-db80fcb51f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт данных с БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "289f44b2-aa91-427a-bae1-804fda766c6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM dataset\")\n",
    "df = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e844d22-7e5c-40ac-bc69-b4db867dc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание датафрейма и проверка пустых значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bd99097c-7eec-44bc-b0ff-2f61b5d15631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      xmin  ymin  xmax  ymax         class                file  width  height\n",
      "0      804   298   860   365  missing_hole  01_missing_hole_05   3034    1586\n",
      "1      279   294   353   374  missing_hole  01_missing_hole_05   3034    1586\n",
      "2     1068  1051  1110  1107  missing_hole  01_missing_hole_05   3034    1586\n",
      "3     1613   392  1677   460  missing_hole  01_missing_hole_05   3034    1586\n",
      "4     1062  1047  1117  1112  missing_hole  01_missing_hole_12   3034    1586\n",
      "...    ...   ...   ...   ...           ...                 ...    ...     ...\n",
      "2948  2714  1178  2740  1204  open_circuit  01_open_circuit_12   3034    1586\n",
      "2949  1706   587  1732   613  open_circuit  01_open_circuit_12   3034    1586\n",
      "2950   466  2235   546  2313  open_circuit  04_open_circuit_02   3056    2464\n",
      "2951   421  1722   502  1779  open_circuit  04_open_circuit_02   3056    2464\n",
      "2952   128  1228   197  1306  open_circuit  04_open_circuit_02   3056    2464\n",
      "\n",
      "[2953 rows x 8 columns]\n",
      "xmin      0\n",
      "ymin      0\n",
      "xmax      0\n",
      "ymax      0\n",
      "class     0\n",
      "file      0\n",
      "width     0\n",
      "height    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(data=df, columns=[\"xmin\",\"ymin\", \"xmax\", \"ymax\", \"class\", \"file\", \"width\", \"height\"])\n",
    "print(data)\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "346a9b03-ea7a-470c-86b8-1c148fffbb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение датасета на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "472fd1f7-16d1-4690-9381-e3424ca840ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, shuffle=True, test_size=0.2, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "16c58f24-adbb-46ab-ac0f-83dda599727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование категориальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "13fd15b3-a532-4889-9a27-a6a1d32bf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_la = {\"missing_hole\": 0, \"mouse_bite\": 1, \"open_circuit\":2, \"short\": 3, 'spur': 4,'spurious_copper':5}\n",
    "\n",
    "train[\"class\"] = train[\"class\"].apply(lambda x: classes_la[x])\n",
    "test[\"class\"] = test[\"class\"].apply(lambda x: classes_la[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "52873858-9521-49ab-9aa4-b5e81c2f06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Группировка набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c9fa5487-f3d2-4e9d-9910-45af6e77a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "df_grp = df.groupby(['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7651a800-71b5-4ff3-a174-a6de11685c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка изображений и датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "80ce0584-cd69-4446-a5d2-96752ed49d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image_name):\n",
    "    print(image_name)\n",
    "    image_group = df_grp.get_group(image_name)\n",
    "    bbox = image_group.loc[:,['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "    path =\"./PCB_DATASET/images/\"\n",
    "    if \"missing\" in name.split('_'):\n",
    "        path += 'Missing_hole/'\n",
    "    if \"mouse\" in name.split('_'):\n",
    "        path += 'Mouse_bite/'\n",
    "    if \"open\" in name.split('_'):\n",
    "        path += 'Open_circuit/'\n",
    "    if \"short\" in name.split('_'):\n",
    "        path += 'Short/'\n",
    "    if \"spur\" in name.split('_'):\n",
    "        path += 'Spur/'\n",
    "    if \"spurious\" in name.split('_'):\n",
    "        path += 'Spurious_copper/'\n",
    "   \n",
    "    img = immg.imread(path+\"\"+name+'.jpg')\n",
    "    fig,ax = plt.subplots(figsize=(18,10))\n",
    "    ax.imshow(img,cmap='binary')\n",
    "    for i in range(len(bbox)):\n",
    "        box = bbox.iloc[i].values\n",
    "        x,y,w,h = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
    "        rect = matplotlib.patches.Rectangle((x,y),w,h,linewidth=1,edgecolor='r',facecolor='none',)\n",
    "        ax.add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b90cb0fc-6d86-418e-a994-6eb935439ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение класса для создания тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "09f1088b-d383-4dcb-ae99-b09db8c632c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fcbData(object):\n",
    "    def __init__(self, df, IMG_DIR, transforms): \n",
    "        self.df = df\n",
    "        self.img_dir = IMG_DIR\n",
    "        self.image_ids = self.df['file'].unique().tolist()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        a = ''\n",
    "        if \"missing\" in image_id.split('_'):\n",
    "            a = 'Missing_hole/'\n",
    "        elif \"mouse\" in image_id.split('_'):\n",
    "            a = 'Mouse_bite/'\n",
    "        elif \"open\" in image_id.split('_'):\n",
    "            a = 'Open_circuit/'\n",
    "        elif \"short\" in image_id.split('_'):\n",
    "            a = 'Short/'\n",
    "        elif \"spur\" in image_id.split('_'):\n",
    "            a = 'Spur/'\n",
    "        elif \"spurious\" in image_id.split('_'):\n",
    "            a = 'Spurious_copper/'\n",
    "        image_values = self.df[self.df['file'] == image_id]\n",
    "        image = cv2.imread(self.img_dir+a+image_id+\".jpg\",cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        \n",
    "        boxes = image_values[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy()\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        \n",
    "        labels = image_values[\"class\"].values\n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([idx])\n",
    "        target['area'] = torch.as_tensor(area, dtype=torch.float32)\n",
    "        target['iscrowd'] = torch.zeros(len(classes_la), dtype=torch.int64)\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "        \n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            \n",
    "            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        return torch.tensor(image), target, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "73acb939-561d-44f7-8f8e-c9bde3c9e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8eb0c210-8a9d-4ac7-a38d-1a4c636245df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка изображений для преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d6052755-eca5-4efb-8d6f-41b0c114d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"./PCB_DATASET/images/\"\n",
    "fcb_dataset   = fcbData(df, path, get_train_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b9518745-d710-4dc7-a0dd-e07f1448f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3fb738d9-16a3-48e0-9330-1a2c64308fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = fcbData(df, path, get_train_transform())\n",
    "indices = torch.randperm(len(train_dataset)).tolist()\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=6,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5acb5ece-981b-41bd-8cdb-2a46845e726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели R-CNN ResNet-50 для обнаружения объектов и классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "007aaf08-35a1-4ff1-9f20-4cef2a228856",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4ce25b12-1a66-41a5-946d-91b5398eabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение устройства обработки и загрузка оптимизаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a166ed5d-634e-4eca-97f1-5e2f27329ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ac2a7d4a-380d-41cd-9f1f-049f39063bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=0.0001, weight_decay=0.0005,)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d93dc9ff-f41b-4f62-a371-1ce4ac0bfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установлены 2 эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0e069e17-fe58-4f44-b769-6d6214c32075",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3a99b6b2-42d9-46bb-a280-4c55bfb36d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "368574e7-1be3-4721-ab77-cdf5a74b5514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8259a51eee84ea8972aff5bda90804d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 loss: 0.095889732020452\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080c1f4ec4984ef98509868e1c4fae96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 loss: 0.009387831319037344\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "best_epoch = 1\n",
    "min_loss = sys.maxsize\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    tk = tqdm(train_data_loader)\n",
    "    model.train();\n",
    "    for images, targets, image_ids in tk:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tk.set_postfix(train_loss=loss_value)\n",
    "    tk.close()\n",
    "\n",
    "    print(f\"Epoch #{epoch} loss: {loss_value}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "26bb8588-c299-426f-bc24-2c4590add1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'pcbdetection.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2a29196e-5630-481c-9098-fc388b9f699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ddfe9748-b185-4c05-8810-2b7da1cb9385",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true =[]\n",
    "y_pred = []\n",
    "for i in range(50):\n",
    "    img,target,_ = test_dataset[i]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img.to(device)])[0]\n",
    "        y_true.append(target['labels'][0])\n",
    "        y_pred.append(prediction['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "30c3093d-6689-40ce-b3c0-f0908f93c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_pred = []\n",
    "for v in y_pred:\n",
    "    yy_pred.append(v.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c538284e-f3c4-4b9b-b497-cb3927905208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a99c72c0-4787-4253-8d1e-1f6caecc1741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0,  1,  0,  0],\n",
       "       [ 0,  7,  2,  0,  0,  0],\n",
       "       [ 0,  0,  9,  0,  0,  0],\n",
       "       [ 0,  0,  0,  9,  0,  0],\n",
       "       [ 0,  1,  0,  0,  2,  6],\n",
       "       [ 0,  0,  0,  0,  0, 12]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, yy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5ef218dc-7a14-4f1f-8691-10b3a7900420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отчет о классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d669e260-94e4-49c8-959d-537849aad846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.78      0.78      0.78         9\n",
      "           2       0.82      1.00      0.90         9\n",
      "           3       0.90      1.00      0.95         9\n",
      "           4       1.00      0.22      0.36         9\n",
      "           5       0.67      1.00      0.80        12\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.69      0.67      0.63        50\n",
      "weighted avg       0.79      0.78      0.73        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, yy_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
